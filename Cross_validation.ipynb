{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Cross Validation\n",
    "\n",
    "### Paul Anzel, 10-20-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: I have a few different methods I'd like to try and do a fit (e.g. $k$-nearest-neighbors vs support-vector-machine) and I want to see which gives me better accuracy.\n",
    "\n",
    "Or...\n",
    "\n",
    "Problem: I don't have too much data, and I have a lot of possible parameters I could use for my statistical model fits. How can I choose among them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try fitting to some data with an initial model\n",
    "\n",
    "$y = \\beta_1 x_2 + \\beta_2 x_3 + \\beta_3 x_7 + 5$\n",
    "\n",
    "$\\beta_2 = 5$\n",
    "\n",
    "$\\beta_3 = 10$ <-- the most important one\n",
    "\n",
    "$\\beta_7 = 0.2$\n",
    "\n",
    "But pretend I don't know about the values of the $\\beta$'s. We have $\\bar x = [x_1, ..., x_{10}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "rd.seed(10000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "beta2 = 5\n",
    "beta3 = 10\n",
    "beta7 = 2\n",
    "intercept = 50\n",
    "\n",
    "eta = 40  # Random parameter\n",
    "\n",
    "x1 = 10*(rd.rand(N) - .5)\n",
    "x2 = 10*(rd.rand(N) - .5)\n",
    "x3 = 10*(rd.rand(N) - .5)\n",
    "x4 = 10*(rd.rand(N) - .5)\n",
    "x5 = 10*(rd.rand(N) - .5)\n",
    "x6 = 10*(rd.rand(N) - .5)\n",
    "x7 = 10*(rd.rand(N) - .5)\n",
    "x8 = 10*(rd.rand(N) - .5)\n",
    "x9 = 10*(rd.rand(N) - .5)\n",
    "x10 = 10*(rd.rand(N) - .5)\n",
    "\n",
    "\n",
    "yvals = intercept + beta2*x2 + beta3*x3 + beta7*x7 + eta*rd.rand(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109814390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anzelp/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAERCAYAAAC5PCsTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107da1210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sval = np.ones((N,))*50\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].scatter(x2, yvals, s=sval, color='g')\n",
    "axes[0].set_xlabel('x2')\n",
    "axes[0].set_ylabel('y')\n",
    "\n",
    "axes[1].scatter(x3, yvals, s=sval, color='g')\n",
    "axes[1].set_xlabel('x3')\n",
    "\n",
    "axes[2].scatter(x7, yvals, s=sval, color='g')\n",
    "axes[2].set_xlabel('x7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.7891585249\n",
      "[ -2.89937564   4.25268449  13.84027441   4.29652734   1.43866066\n",
      "   5.19036671  -1.59254485  -5.60143668  -4.34299036  -0.45154377]\n",
      "0.969906893742\n"
     ]
    }
   ],
   "source": [
    "x_collate = np.vstack((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10)).T\n",
    "\n",
    "clf_standard = linear_model.LinearRegression()\n",
    "clf_standard.fit(x_collate, yvals)\n",
    "print(clf_standard.intercept_)\n",
    "print(clf_standard.coef_)\n",
    "print(clf_standard.score(x_collate, yvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 only R^2: 0.09\n",
      "x2 only R^2: 0.17\n",
      "x3 only R^2: 0.74\n",
      "x4 only R^2: 0.02\n",
      "x5 only R^2: 0.00\n",
      "x6 only R^2: 0.00\n",
      "x7 only R^2: 0.05\n",
      "x8 only R^2: 0.01\n",
      "x9 only R^2: 0.03\n",
      "x10 only R^2: 0.07\n"
     ]
    }
   ],
   "source": [
    "for ind in range(10):\n",
    "    exec('xtest = x%d' % (ind + 1))\n",
    "    clf_simple = linear_model.LinearRegression()\n",
    "    clf_simple.fit(xtest.reshape((N,1)), yvals.reshape((N,1)))\n",
    "    print('x%d only R^2: %.2f'\n",
    "          % ((ind+1), clf_simple.score(xtest.reshape((N,1)), yvals.reshape((N,1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most conventional way of doing things. In holdout, the data is split into two sets, the training set and the test set (say 70%/30% split). We run our fit on the training set, and then see what error values you get when you apply the fit to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try with a score R^2 = 0.50\n",
      "Second time with a score R^2 = -7.81\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\n",
    "    x_collate, yvals, test_size=3, random_state=0)\n",
    "\n",
    "clf_holdout=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "print('First try with a score R^2 = %.2f'\n",
    "      % clf_holdout.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\n",
    "    x_collate, yvals, test_size=3, random_state=10)\n",
    "\n",
    "clf_holdout=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "print('Second time with a score R^2 = %.2f'\n",
    "      % clf_holdout.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sub-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do holdout $k$ times (selecting your sets randomly each time). After having done this, take the average of your errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  4  6 11  2 10  9 14  8 12 13  7] TEST: [5 3 1]\n",
      "TRAIN: [ 3  0 13 12  2  9 14  1  8  7 10  6] TEST: [11  4  5]\n",
      "TRAIN: [ 8  2  6  0  4 10  9 13 11  1  3  7] TEST: [14  5 12]\n",
      "TRAIN: [ 3  8  9 10 13  5  2 11  4  6 12  1] TEST: [ 7  0 14]\n",
      "TRAIN: [ 2  9 13  0  5 12  3  6  8 11  4 10] TEST: [14  7  1]\n",
      "TRAIN: [ 4  7 11  5 14 13  8  3  0  2 12  1] TEST: [ 9 10  6]\n",
      "TRAIN: [11  3  9  8  5  6  4  7 12  0  2 13] TEST: [ 1 14 10]\n",
      "TRAIN: [ 4 13  8  3  7 11 14  0 12  9  5  2] TEST: [ 6 10  1]\n",
      "TRAIN: [10  5  1  8 12  7 14  9  3 13 11  0] TEST: [2 4 6]\n",
      "TRAIN: [14  3 13  2  8 11  6  1  7  4  9 12] TEST: [ 5  0 10]\n",
      "-2.79454396274\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "\n",
    "ss = cross_validation.ShuffleSplit(\n",
    "    N, n_iter=n_iter, test_size=3, random_state=1337)\n",
    "\n",
    "R2_list = np.empty((len(ss),))\n",
    "ind = 0\n",
    "\n",
    "for train, test in ss:\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[ind] = clf.score(X_test, Y_test)\n",
    "    ind += 1\n",
    "    \n",
    "print(R2_list.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV (Leave-one-out-cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this technique, you'll take one data point out ($x_i$), and run your model fitting $\\hat y_{-i} = f(X_{-i})$ on the rest of the set. Calculate the error $e_{-i} = \\hat y_{-i} - y_i$. Next, repeat the process for each of the other data points $i = 1, ..., n$. Average the results, and you have your CV statistic.\n",
    "\n",
    "You can also average things like $R^2$ statistics instead (using scikit-learn's `clf.score()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [1]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [2]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [3]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [4]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [5]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [6]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [8]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [9]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [10]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14] TEST: [11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14] TEST: [12]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14] TEST: [13]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] TEST: [14]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "loo = cross_validation.LeaveOneOut(N)\n",
    "\n",
    "R2_list = np.empty((len(loo),))\n",
    "ind = 0\n",
    "\n",
    "for train, test in loo:\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[ind] = clf.score(X_test, Y_test)\n",
    "    ind += 1\n",
    "    \n",
    "print(R2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, we can't call score on one point! We'll need to actually compute the mean squared error instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [1]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [2]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [3]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [4]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [5]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [6]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [8]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [9]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [10]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14] TEST: [11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14] TEST: [12]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14] TEST: [13]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] TEST: [14]\n",
      "[ -3.24542226 -13.38125825 -21.64894009   5.55600438  22.73334596\n",
      "  10.09953798  29.88661617 -25.58221522  43.04950163  19.79733414\n",
      " -23.96414228 -46.81047233   7.87252212  50.05086373 -17.9464285 ]\n",
      "MSE = 717.03\n"
     ]
    }
   ],
   "source": [
    "err_list = np.empty((len(loo),))\n",
    "ind = 0\n",
    "\n",
    "for train, test in loo:\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    err_list[ind] = Y_test - clf.predict(X_test)\n",
    "    ind += 1\n",
    "    \n",
    "print(err_list)\n",
    "print('MSE = %.2f' % ((1/N)*(np.sum(err_list**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a bit slow to do if you're implementing your own routine, but if you've got a linear regression system\n",
    "\n",
    "$y = X \\bar \\beta + \\bar e$\n",
    "\n",
    "You would (in a typical least-squares) compute\n",
    "\n",
    "$\\hat \\beta = (X^T X)^{-1} X^T y$\n",
    "\n",
    "$\\hat y = X \\hat \\beta = X (X^T X)^{-1} X^T y = H y$\n",
    "\n",
    "And the cross-validation statistic can be computed\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=0}^n [e_i / (1-H_{ii})]^2$\n",
    "\n",
    "Where $e_i$ are the residuals of the fit to all $n$ points.\n",
    "\n",
    "(I cannot yet find if scikit learn does this for you...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.:\n",
    "- LOOCV will not consistently (as $n \\rightarrow \\infty$) settle on a fit model ([Jun Shao, 1993](https://www.jstor.org/stable/2290328?&seq=1#page_scan_tab_contents)). This may not be a problem, as the real world barely follows nice models anyway.\n",
    "- LOOCV might be sensitive (in which model you have) to your data, so be careful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LpOCV (Leave-p-out-cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an extension of above, except rather than leaving 1 data point out and running $n$ different fits, you leave $p$ units out and do $\\frac{n!}{p! (n-p)!}$ (choosing all possible $p$-sized subsets) different statistical fits. Note that this can become fairly unweildly is $n$ is decently sized, so be warned.\n",
    "\n",
    "Like LOOCV, you'll run your fits on the n-choose-p take-p-out data sets, find the error on them, and average out all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 1]\n",
      "TRAIN: [ 1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 2]\n",
      "TRAIN: [ 1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 3]\n",
      "TRAIN: [ 1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [0 4]\n",
      "TRAIN: [ 1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [0 5]\n",
      "TRAIN: [ 1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [0 6]\n",
      "TRAIN: [ 1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [0 7]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [0 8]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [0 9]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [ 0 10]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "p_count = 2\n",
    "\n",
    "lpo = cross_validation.LeavePOut(N, p=p_count)\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for train, test in lpo:\n",
    "    if ind < 10:\n",
    "        print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    elif ind == 10:\n",
    "        print('...')\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    # ...\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different extension of LOOCV/LpOCV. Shuffle your data and divide it into $k$ subsets. Run your fitting $k$ times, where the $k^{th}$ subset is your test set and the rest are your training sets. Average your error among all of the different sets, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 5  6  7  8  9 10 11 12 13 14] TEST: [0 1 2 3 4]\n",
      "TRAIN: [ 0  1  2  3  4 10 11 12 13 14] TEST: [5 6 7 8 9]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11 12 13 14]\n",
      "[-7.65582374  0.51350169 -1.46836761]\n"
     ]
    }
   ],
   "source": [
    "n_folds = 3\n",
    "\n",
    "kf = cross_validation.KFold(N, n_folds=n_folds)\n",
    "\n",
    "R2_list = np.empty((len(kf),))\n",
    "ind = 0\n",
    "\n",
    "for train, test in kf:\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[ind] = clf.score(X_test, Y_test)\n",
    "    ind += 1\n",
    "    \n",
    "print(R2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trade off:\n",
    "\n",
    "- If you have a lot of fits (e.g. $k$ is pretty large in $k$-fold) the bias of your error estimator will be small (you'll be accurate) but it'll have large variance (low precision). This can also possibly take a long time to compute.\n",
    "- If you have a few fits (small $k$) the bias will be larger (higher than the true error rate) but will have less variance. Faster to compute.\n",
    "\n",
    "For large datasets, $k = 3$ is pretty reasonable. For very small ones, look to LOOCV. $k=10$ is a common choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn does this for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.65582374  0.51350169 -1.46836761]\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    x_collate,\n",
    "    yvals,\n",
    "    cv=3 # Defaults to 3-Fold, can put in other generator (as above)\n",
    ")\n",
    "print(cv)\n",
    "# Note this is the same result as what we got for 3-Fold above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.24542226 -13.38125825 -21.64894009   5.55600438  22.73334596\n",
      "  10.09953798  29.88661617 -25.58221522  43.04950163  19.79733414\n",
      " -23.96414228 -46.81047233   7.87252212  50.05086373 -17.9464285 ]\n"
     ]
    }
   ],
   "source": [
    "# Since we need to do \n",
    "\n",
    "cv2 = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(),\n",
    "    x_collate,\n",
    "    yvals,\n",
    "    cv=cross_validation.LeaveOneOut(N)\n",
    ")\n",
    "\n",
    "err_vals = yvals - cv2\n",
    "print(err_vals)\n",
    "# Note this is the same error values we got for our LOOCV above\n",
    "# We can subsequently calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good R^2: 0.78\n",
      "Bad R^2: -0.87\n",
      "Good MSE: 164.56\n",
      "Bad MSE: 1738.36\n"
     ]
    }
   ],
   "source": [
    "xcoll_good = np.vstack((x2, x3)).T\n",
    "xcoll_bad = np.vstack((x1, x9)).T\n",
    "\n",
    "cv_good_score = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_good,\n",
    "    yvals,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "cv_bad_score = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_bad,\n",
    "    yvals,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print('Good R^2: %.2f' % np.mean(cv_good_score))\n",
    "print('Bad R^2: %.2f' % np.mean(cv_bad_score))\n",
    "\n",
    "cv_good_pred = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_good,\n",
    "    yvals,\n",
    "    cv=loo\n",
    ")\n",
    "good_sq_err = (yvals - cv_good_pred)**2\n",
    "print('Good MSE: %.2f' % ((1/N)*np.sum(good_sq_err)))\n",
    "\n",
    "cv_bad_pred = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_bad,\n",
    "    yvals,\n",
    "    cv=loo\n",
    ")\n",
    "bad_sq_err = (yvals - cv_bad_pred)**2\n",
    "print('Bad MSE: %.2f' % ((1/N)*np.sum(bad_sq_err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing time series, you want to test on the most recent data (so you're not just interpolating. Plus, it's clear that the data is not IID any longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One technique:\n",
    "- Fit model to data $y_1, ..., y_t$. Find the forecast $\\hat y_{t+1}$ and compute prediction error $e_{t+1}$.\n",
    "- Repeat this for $t = m, ..., n-1$ where $m$ is the minimum number of steps needed to fit the model.\n",
    "- Average errors (as before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Some point I'll put a clever code example here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other notes:\n",
    "- There are Stratification techniques, where you split your different categories (e.g. for classification) so that you get a (roughly) even partition of your different classes in your test groups (e.g. `cross_validation.StratifiedKFold`).\n",
    "- Similarly, for labeled categories you have methods like Leave-One-Label-Out and Leave-P-Labels-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- http://robjhyndman.com/hyndsight/crossvalidation/\n",
    "- https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
