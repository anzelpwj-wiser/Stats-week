{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Cross Validation\n",
    "\n",
    "### Paul Anzel, 10-20-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: I have a few different methods I'd like to try and do a fit (e.g. $k$-nearest-neighbors vs support-vector-machine) and I want to see which gives me better accuracy.\n",
    "\n",
    "Or...\n",
    "\n",
    "Problem: I don't have too much data, and I have a lot of possible parameters I could use for my statistical model fits. How can I choose among them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try fitting to some data with an initial model\n",
    "\n",
    "$y = \\beta_1 x_2 + \\beta_2 x_3 + \\beta_3 x_7 + 5$\n",
    "\n",
    "$\\beta_2 = 5$\n",
    "\n",
    "$\\beta_3 = 10$ <-- the most important one\n",
    "\n",
    "$\\beta_7 = 0.2$\n",
    "\n",
    "But pretend I don't know about the values of the $\\beta$'s. We have $\\bar x = [x_1, ..., x_{10}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "rd.seed(10000)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "beta2 = 5\n",
    "beta3 = 10\n",
    "beta7 = 2\n",
    "intercept = 50\n",
    "\n",
    "eta = 40  # Random parameter\n",
    "\n",
    "x1 = 10*(rd.rand(N) - .5)\n",
    "x2 = 10*(rd.rand(N) - .5)\n",
    "x3 = 10*(rd.rand(N) - .5)\n",
    "x4 = 10*(rd.rand(N) - .5)\n",
    "x5 = 10*(rd.rand(N) - .5)\n",
    "x6 = 10*(rd.rand(N) - .5)\n",
    "x7 = 10*(rd.rand(N) - .5)\n",
    "x8 = 10*(rd.rand(N) - .5)\n",
    "x9 = 10*(rd.rand(N) - .5)\n",
    "x10 = 10*(rd.rand(N) - .5)\n",
    "\n",
    "\n",
    "yvals = intercept + beta2*x2 + beta3*x3 + beta7*x7 + eta*rd.rand(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1095fbc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anzelp/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAERCAYAAAC5PCsTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10952dad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sval = np.ones((N,))*50\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].scatter(x2, yvals, s=sval, color='g')\n",
    "axes[0].set_xlabel('x2')\n",
    "axes[0].set_ylabel('y')\n",
    "\n",
    "axes[1].scatter(x3, yvals, s=sval, color='g')\n",
    "axes[1].set_xlabel('x3')\n",
    "\n",
    "axes[2].scatter(x7, yvals, s=sval, color='g')\n",
    "axes[2].set_xlabel('x7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.7891585249\n",
      "[ -2.89937564   4.25268449  13.84027441   4.29652734   1.43866066\n",
      "   5.19036671  -1.59254485  -5.60143668  -4.34299036  -0.45154377]\n",
      "0.969906893742\n"
     ]
    }
   ],
   "source": [
    "x_collate = np.vstack((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10)).T\n",
    "\n",
    "clf_standard = linear_model.LinearRegression()\n",
    "clf_standard.fit(x_collate, yvals)\n",
    "print(clf_standard.intercept_)\n",
    "print(clf_standard.coef_)\n",
    "print(clf_standard.score(x_collate, yvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 only R^2: 0.09\n",
      "x2 only R^2: 0.17\n",
      "x3 only R^2: 0.74\n",
      "x4 only R^2: 0.02\n",
      "x5 only R^2: 0.00\n",
      "x6 only R^2: 0.00\n",
      "x7 only R^2: 0.05\n",
      "x8 only R^2: 0.01\n",
      "x9 only R^2: 0.03\n",
      "x10 only R^2: 0.07\n"
     ]
    }
   ],
   "source": [
    "for ind in range(10):\n",
    "    exec('xtest = x%d' % (ind + 1))\n",
    "    clf_simple = linear_model.LinearRegression()\n",
    "    clf_simple.fit(xtest.reshape((N,1)), yvals.reshape((N,1)))\n",
    "    print('x%d only R^2: %.2f'\n",
    "          % ((ind+1), clf_simple.score(xtest.reshape((N,1)), yvals.reshape((N,1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most conventional way of doing things. In holdout, the data is split into two sets, the training set and the test set (say 70%/30% split). We run our fit on the training set, and then see what error values you get when you apply the fit to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try with a score R^2 = 0.50\n",
      "Second time with a score R^2 = -7.81\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\n",
    "    x_collate, yvals, test_size=3, random_state=0)\n",
    "\n",
    "clf_holdout=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "print('First try with a score R^2 = %.2f'\n",
    "      % clf_holdout.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\n",
    "    x_collate, yvals, test_size=3, random_state=10)\n",
    "\n",
    "clf_holdout=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "print('Second time with a score R^2 = %.2f'\n",
    "      % clf_holdout.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sub-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do holdout $k$ times (selecting your sets randomly each time). After having done this, take the average of your errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  4  6 11  2 10  9 14  8 12 13  7] TEST: [5 3 1]\n",
      "TRAIN: [ 3  0 13 12  2  9 14  1  8  7 10  6] TEST: [11  4  5]\n",
      "TRAIN: [ 8  2  6  0  4 10  9 13 11  1  3  7] TEST: [14  5 12]\n",
      "TRAIN: [ 3  8  9 10 13  5  2 11  4  6 12  1] TEST: [ 7  0 14]\n",
      "TRAIN: [ 2  9 13  0  5 12  3  6  8 11  4 10] TEST: [14  7  1]\n",
      "TRAIN: [ 4  7 11  5 14 13  8  3  0  2 12  1] TEST: [ 9 10  6]\n",
      "TRAIN: [11  3  9  8  5  6  4  7 12  0  2 13] TEST: [ 1 14 10]\n",
      "TRAIN: [ 4 13  8  3  7 11 14  0 12  9  5  2] TEST: [ 6 10  1]\n",
      "TRAIN: [10  5  1  8 12  7 14  9  3 13 11  0] TEST: [2 4 6]\n",
      "TRAIN: [14  3 13  2  8 11  6  1  7  4  9 12] TEST: [ 5  0 10]\n",
      "-2.79454396274\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "\n",
    "ss = cross_validation.ShuffleSplit(\n",
    "    N, n_iter=n_iter, test_size=3, random_state=1337)\n",
    "\n",
    "R2_list = np.empty((len(ss),))\n",
    "\n",
    "for ind, (train, test) in enumerate(ss):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[ind] = clf.score(X_test, Y_test)\n",
    "    \n",
    "print(R2_list.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV (Leave-one-out-cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this technique, you'll take one data point out ($x_i$), and run your model fitting $\\hat y_{-i} = f(X_{-i})$ on the rest of the set. Calculate the error $e_{-i} = \\hat y_{-i} - y_i$. Next, repeat the process for each of the other data points $i = 1, ..., n$. Average the results, and you have your CV statistic.\n",
    "\n",
    "You can also average things like $R^2$ statistics instead (using scikit-learn's `clf.score()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [1]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [2]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [3]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [4]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [5]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [6]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [8]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [9]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [10]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14] TEST: [11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14] TEST: [12]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14] TEST: [13]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] TEST: [14]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "loo = cross_validation.LeaveOneOut(N)\n",
    "\n",
    "R2_list = np.empty((len(loo),))\n",
    "\n",
    "for ind, (train, test) in enumerate(loo):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[ind] = clf.score(X_test, Y_test)\n",
    "    \n",
    "print(R2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, we can't call score on one point! We'll need to actually compute the mean squared error instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [1]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [2]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [3]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [4]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [5]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [6]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [8]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [9]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [10]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14] TEST: [11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14] TEST: [12]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14] TEST: [13]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13] TEST: [14]\n",
      "[ -3.24542226 -13.38125825 -21.64894009   5.55600438  22.73334596\n",
      "  10.09953798  29.88661617 -25.58221522  43.04950163  19.79733414\n",
      " -23.96414228 -46.81047233   7.87252212  50.05086373 -17.9464285 ]\n",
      "MSE = 717.03\n"
     ]
    }
   ],
   "source": [
    "err_list = np.empty((len(loo),))\n",
    "\n",
    "for ind, (train, test) in enumerate(loo):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    err_list[ind] = Y_test - clf.predict(X_test)\n",
    "    \n",
    "print(err_list)\n",
    "print('MSE = %.2f' % ((1/N)*(np.sum(err_list**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a bit slow to do if you're implementing your own routine, but if you've got a linear regression system\n",
    "\n",
    "$y = X \\bar \\beta + \\bar e$\n",
    "\n",
    "You would (in a typical least-squares) compute\n",
    "\n",
    "$\\hat \\beta = (X^T X)^{-1} X^T y$\n",
    "\n",
    "$\\hat y = X \\hat \\beta = X (X^T X)^{-1} X^T y = H y$\n",
    "\n",
    "And the cross-validation statistic can be computed\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=0}^n [e_i / (1-H_{ii})]^2$\n",
    "\n",
    "Where $e_i$ are the residuals of the fit to all $n$ points.\n",
    "\n",
    "(I cannot yet find if scikit learn does this for you...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.:\n",
    "- LOOCV will not consistently (as $n \\rightarrow \\infty$) settle on a fit model ([Jun Shao, 1993](https://www.jstor.org/stable/2290328?&seq=1#page_scan_tab_contents)). This may not be a problem, as the real world barely follows nice models anyway.\n",
    "- LOOCV might be sensitive (in which model you have) to your data, so be careful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LpOCV (Leave-p-out-cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an extension of above, except rather than leaving 1 data point out and running $n$ different fits, you leave $p$ units out and do $\\frac{n!}{p! (n-p)!}$ (choosing all possible $p$-sized subsets) different statistical fits. Note that this can become fairly unweildly is $n$ is decently sized, so be warned.\n",
    "\n",
    "Like LOOCV, you'll run your fits on the n-choose-p take-p-out data sets, find the error on them, and average out all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 1]\n",
      "TRAIN: [ 1  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 2]\n",
      "TRAIN: [ 1  2  4  5  6  7  8  9 10 11 12 13 14] TEST: [0 3]\n",
      "TRAIN: [ 1  2  3  5  6  7  8  9 10 11 12 13 14] TEST: [0 4]\n",
      "TRAIN: [ 1  2  3  4  6  7  8  9 10 11 12 13 14] TEST: [0 5]\n",
      "TRAIN: [ 1  2  3  4  5  7  8  9 10 11 12 13 14] TEST: [0 6]\n",
      "TRAIN: [ 1  2  3  4  5  6  8  9 10 11 12 13 14] TEST: [0 7]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  9 10 11 12 13 14] TEST: [0 8]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  8 10 11 12 13 14] TEST: [0 9]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 11 12 13 14] TEST: [ 0 10]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "p_count = 2\n",
    "\n",
    "lpo = cross_validation.LeavePOut(N, p=p_count)\n",
    "\n",
    "for ind, (train, test) in enumerate(lpo):\n",
    "    if ind < 10:\n",
    "        print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    elif ind == 10:\n",
    "        print('...')\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    # ... usual code as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different extension of LOOCV/LpOCV. Shuffle your data and divide it into $k$ subsets. Run your fitting $k$ times, where the $k^{th}$ subset is your test set and the rest are your training sets. Average your error among all of the different sets, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 5  6  7  8  9 10 11 12 13 14] TEST: [0 1 2 3 4]\n",
      "TRAIN: [ 0  1  2  3  4 10 11 12 13 14] TEST: [5 6 7 8 9]\n",
      "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11 12 13 14]\n",
      "[-7.65582374  0.51350169 -1.46836761]\n"
     ]
    }
   ],
   "source": [
    "n_folds = 3\n",
    "\n",
    "kf = cross_validation.KFold(N, n_folds=n_folds)\n",
    "\n",
    "R2_list = np.empty((len(kf),))\n",
    "\n",
    "for idx, (train, test) in enumerate(kf):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    X_train = x_collate[train, :]\n",
    "    X_test = x_collate[test, :]\n",
    "    Y_train = yvals[train]\n",
    "    Y_test = yvals[test]\n",
    "    clf=linear_model.LinearRegression().fit(X_train, Y_train)\n",
    "    R2_list[idx] = clf.score(X_test, Y_test)\n",
    "    \n",
    "print(R2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trade off:\n",
    "\n",
    "- If you have a lot of fits (e.g. $k$ is pretty large in $k$-fold) the bias of your error estimator will be small (you'll be accurate) but it'll have large variance (low precision). This can also possibly take a long time to compute.\n",
    "- If you have a few fits (small $k$) the bias will be larger (higher than the true error rate) but will have less variance. Faster to compute.\n",
    "\n",
    "For large datasets, $k = 3$ is pretty reasonable. For very small ones, look to LOOCV. $k=10$ is a common choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn does this for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.65582374  0.51350169 -1.46836761]\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    x_collate,\n",
    "    yvals,\n",
    "    cv=3 # Defaults to 3-Fold, can put in other generator (as above)\n",
    ")\n",
    "print(cv)\n",
    "# Note this is the same result as what we got for 3-Fold above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.24542226 -13.38125825 -21.64894009   5.55600438  22.73334596\n",
      "  10.09953798  29.88661617 -25.58221522  43.04950163  19.79733414\n",
      " -23.96414228 -46.81047233   7.87252212  50.05086373 -17.9464285 ]\n"
     ]
    }
   ],
   "source": [
    "# Since we need to do \n",
    "\n",
    "cv2 = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(),\n",
    "    x_collate,\n",
    "    yvals,\n",
    "    cv=cross_validation.LeaveOneOut(N)\n",
    ")\n",
    "\n",
    "err_vals = yvals - cv2\n",
    "print(err_vals)\n",
    "# Note this is the same error values we got for our LOOCV above\n",
    "# We can subsequently calculate MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good R^2: 0.78\n",
      "Bad R^2: -0.87\n",
      "Good MSE: 164.56\n",
      "Bad MSE: 1738.36\n"
     ]
    }
   ],
   "source": [
    "xcoll_good = np.vstack((x2, x3)).T\n",
    "xcoll_bad = np.vstack((x1, x9)).T\n",
    "\n",
    "cv_good_score = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_good,\n",
    "    yvals,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "cv_bad_score = cross_validation.cross_val_score(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_bad,\n",
    "    yvals,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print('Good R^2: %.2f' % np.mean(cv_good_score))\n",
    "print('Bad R^2: %.2f' % np.mean(cv_bad_score))\n",
    "\n",
    "cv_good_pred = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_good,\n",
    "    yvals,\n",
    "    cv=loo\n",
    ")\n",
    "good_sq_err = (yvals - cv_good_pred)**2\n",
    "print('Good MSE: %.2f' % ((1/N)*np.sum(good_sq_err)))\n",
    "\n",
    "cv_bad_pred = cross_validation.cross_val_predict(\n",
    "    linear_model.LinearRegression(), # Estimator\n",
    "    xcoll_bad,\n",
    "    yvals,\n",
    "    cv=loo\n",
    ")\n",
    "bad_sq_err = (yvals - cv_bad_pred)**2\n",
    "print('Bad MSE: %.2f' % ((1/N)*np.sum(bad_sq_err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing time series, you want to test on the most recent data (so you're not just interpolating. Plus, it's clear that the data is not IID any longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One technique:\n",
    "- Fit model to data $y_1, ..., y_t$. Find the forecast $\\hat y_{t+1}$ and compute prediction error $e_{t+1}$.\n",
    "- Repeat this for $t = m, ..., n-1$ where $m$ is the minimum number of steps needed to fit the model.\n",
    "- Average errors (as before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Some point I'll put a clever code example here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other notes:\n",
    "- There are Stratification techniques, where you split your different categories (e.g. for classification) so that you get a (roughly) even partition of your different classes in your test groups (e.g. `cross_validation.StratifiedKFold`).\n",
    "- Similarly, for labeled categories you have methods like Leave-One-Label-Out and Leave-P-Labels-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- http://robjhyndman.com/hyndsight/crossvalidation/\n",
    "- https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
