{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hilbert and Hilbert-Huang Transform\n",
    "\n",
    "### Paul Anzel DATEDATEDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with the Fourier transform (and related techniques) is that they're *stationary* methods--specifically, they assume that nothing actually changes in time, it's all just waves perpetually going in to and out of phase. A Fourier series of a music file will tell you that there's a lot of $A \\flat$'s and middle $C$'s, but nothing about when they happen, and it assumes that, like some demented fool, you've decided to play \"The Boys are Back in Town\" over and over on to infinity--and that you've been playing that song since time immemorial. You can ignore this fact in practice, but it is a weird conceptual issue. \n",
    "\n",
    "Or, for a simpler case, assume that you've briefly turned on and off a light-switch. The Fourier transform assumes that the light is always emitting various frequencies, from before you were born until well past the collapse of civilization (and perhaps the demolishing of the light) but it *just so happens* that at all of these times the various frequencies were cancelling each other out until the magic moment that the light is turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.fftpack import fft, fftfreq, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from scipy.signal import hilbert, savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_light = np.arange(-5, 5, 0.05)\n",
    "\n",
    "# This is a bump function, so we have a nice turn off-and-on\n",
    "_f = lambda x: np.exp(-1.0/(1.0-x*x))\n",
    "f = lambda x: np.piecewise(x, [np.abs(x) < 1, np.abs(x) >= 1], [_f, 0.0])\n",
    "\n",
    "y_light = np.cos(x_light*6*np.pi)\n",
    "y_light = y_light*f(x_light)\n",
    "y_fft = fft(y_light)\n",
    "x_fft = fftfreq(len(x_light), 0.05)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "axes[0].plot(x_light, y_light, color='k')\n",
    "axes[0].set_title('Lightbulb', fontsize=20)\n",
    "axes[0].set_xlabel('Time', fontsize=20)\n",
    "axes[1].plot(fftshift(x_fft), fftshift(y_fft), color='r')\n",
    "axes[1].set_xlabel('Freq', fontsize=20)\n",
    "axes[1].set_title('FFT', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is weird. You'd think that, maybe if you filtered the light just right, you could cancel this out (you can't without breaking causality$^*$ but that's another issue) and see the light turning off and on.\n",
    "\n",
    "There are various ways to deal with this; the most common is to window your signal (multiply it by a function that goes to 0 around some point $t$) and take transforms of the signal at different points in time (much like the song visualizers you might see in Winamp and iTunes), giving a *spectrogram*. Other technique include wavelet analysis and using the Wigner distribution function.\n",
    "\n",
    "A final way, and our technique of interest here, is to take a Hilbert transform.\n",
    "\n",
    "$^*$And this causality leads to the [Kramers-Kronig relations](https://en.wikipedia.org/wiki/Kramers%E2%80%93Kronig_relations), which is another Hilbert transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hilbert transform of a function $f(t)$ is the transformation\n",
    "\n",
    "$$ \\mathcal{H}(f)(t) = \\frac{1}{\\pi} PV \\int_{-\\infty}^{\\infty} \\frac{f(\\tau)}{t - \\tau} d\\tau $$ \n",
    "\n",
    "...so you're convolving your function $f(t)$ with the kernel $K(t) = 1/(\\pi t$).\n",
    "\n",
    "The *PV* in the above equation means Principal Value, which basically is telling you that for the part where $\\tau$ is near $t$, you take an integral with $\\tau$ going to $t - \\epsilon$ and $t + \\epsilon$ with the limit $\\epsilon \\rightarrow 0$. If you wanted to actually solve this for selected functions, you'd probably be using complex analysis with the Residue Theorem and talk about test functions going to 0 at infinity.\n",
    "\n",
    "That is a problem for the mathematicians, and is not something we need to bother with. We can get some basic understanding by looking at tables of transforms [e.g. at Wikipedia](https://en.wikipedia.org/wiki/Hilbert_transform#Table_of_selected_Hilbert_transforms), and most critically understanding that the transform of a cosine gives a sine (at the same frequency) and the transform of a sine gives a negative cosine (same frequency).\n",
    "\n",
    "Plus, we're going to be dealing with numeric data. So you're going to have some convolution kernel like\n",
    "\n",
    "$$[..., -1/5, -1/4 -1/3, -1/2, -1, 0, 1, 1/2, 1/3, 1/4, 1/5, ...]/\\pi$$\n",
    "\n",
    "and you can ignore any weirdness about the $1/t$ blowup and stuff out at infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a Hilbert transform of a function, one will then often create a function $\\tilde{f}(t) = f(t) + i\\mathcal{H}(f)(t)$, which is called the __analytic signal__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, why do we care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine $\\leftrightarrow$ sine bit of the Hilbert Transform and how we make the analytic signal looks a lot like using the Euler identity $\\cos(\\theta) + i\\sin(\\theta) = e^{i \\theta}$. So we can think about this as writing our Analytic Signal as $\\tilde{f}(t) = A(t)e^{i \\theta(t) t}$. Then $A(t)$ gives us the __envelope__ of our signal (our signal is oscillating between the envelope) and $\\frac{d}{dt}\\theta(t)$ is our __instantaneous frequency__ (Specifically, angular frequency. Divide by $2\\pi$ if you want normal frequency).$^*$ These are useful things to deal with.\n",
    "\n",
    "$^*$Actually, this requres the time-scale that $A(t)$ changes at to be much slower than $e^{i \\theta(t) t}$. This is based on something called the Bedrosian Theorem and some refinements to the basic ideas above are discussed [on page 6 here](http://www.msri.org/people/members/2008cc/Projects/Project_5B_Ice_Core_EMD/HuangWu_EMD_RevGeo_2008.pdf). But, for now, the above explanation is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Chirp signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import chirp\n",
    "\n",
    "x_chirp = np.linspace(-5, 15, 1000)\n",
    "dx = x_chirp[1]-x_chirp[0]\n",
    "# chirp_index = np.logical_and(x_chirp > 0, x_chirp <= 10)\n",
    "y_chirp = chirp(x_chirp, 0.5, 10, 1.5, method='linear')\n",
    "y_chirp[x_chirp <= 0] = np.cos(4*x_chirp[x_chirp <= 0])\n",
    "y_chirp[x_chirp >= 10] = np.cos(10*x_chirp[x_chirp >= 10]+np.pi/8)\n",
    "fft_chirp = fft(y_chirp)\n",
    "fftfreqs = fftfreq(len(x_chirp), dx)\n",
    "\n",
    "ya_chirp = hilbert(y_chirp)\n",
    "\n",
    "phase_chirp = np.angle(ya_chirp)\n",
    "phase_chirp = np.unwrap(phase_chirp)\n",
    "instant_freq = savgol_filter(phase_chirp, 3, 1, deriv=1, delta=dx, mode='mirror')/(2*np.pi)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 14))\n",
    "axes[0,0].plot(x_chirp, y_chirp, color='k')\n",
    "axes[0,0].plot(x_chirp, np.imag(ya_chirp), color='r')\n",
    "axes[0,0].set_title('Signal', fontsize=20)\n",
    "axes[0,1].semilogy(fftfreqs[:200], np.abs(fft_chirp[:200]))\n",
    "axes[0,1].set_title('FFT', fontsize=20)\n",
    "axes[1,1].plot(x_chirp, instant_freq, color='g')\n",
    "axes[1,1].set_title('Instantaneous Frequency', fontsize=20)\n",
    "\n",
    "axes[1,0].specgram(y_chirp, Fs=(1.0/dx), xextent=[-5, 15],cmap=plt.cm.viridis)\n",
    "axes[1,0].set_ylim([0.0, 2.5])\n",
    "axes[1,0].set_title('Spectrogram', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fourier Transform clearly shows our frequencies going between 0.6 and 1.6, but doesn't tell us when. The spectrogram shows us the time at which we're at different frequencies, but is fuzzy. The Hilbert Transform, on the other hand, really clearly shows the frequencies at different times, though it has some issues at the boundaries (which could be addressed by mirroring the signal at the end points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Decaying signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_decay = np.linspace(-5, 20, 1000)\n",
    "y_decay = np.exp(-0.5*x_decay)*np.sin(5*x_decay)\n",
    "y_decay[x_decay < 0] = np.sin(5*x_decay[x_decay < 0])\n",
    "\n",
    "ya_decay = hilbert(y_decay)\n",
    "envelope = np.abs(ya_decay)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(x_decay, y_decay, color='k')\n",
    "plt.plot(x_decay, np.imag(ya_decay), color='r')\n",
    "plt.fill_between(x_decay, -envelope, envelope, color='k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again some weirdness at the boundaries (scipy calculates the signal by treating it as periodic, rather than giving the option to mirror) but the decay envelope starting at $t = 0$ is very clear. Since this weirdness-at-the-boundaries is getting to me, let's write our own function to do the mirroring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mirror_hilbert(x, reflect_x=True):\n",
    "    # x should be a (N,) array, but in case you didn't do that\n",
    "    x = x.ravel()\n",
    "    N = len(x)\n",
    "    if reflect_x:\n",
    "        ref_term = -1\n",
    "    else:\n",
    "        ref_term = 1\n",
    "    mirror_x = np.empty(3*N)\n",
    "    mirror_x[:N] = ref_term*x[::-1]\n",
    "    mirror_x[N:(2*N)] = x\n",
    "    mirror_x[(2*N):] = ref_term*x[::-1]\n",
    "    y = hilbert(mirror_x)\n",
    "    ret_y = y[N:(2*N)]\n",
    "    return ret_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ya_decay2 = mirror_hilbert(y_decay, reflect_x=True)\n",
    "envelope2 = np.abs(ya_decay2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(x_decay, y_decay, color='k')\n",
    "plt.plot(x_decay, np.imag(ya_decay2), color='r')\n",
    "plt.fill_between(x_decay, -envelope2, envelope2, color='k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is significantly cleaner. Note that I set the signal to be reflected in the y-axis for this example, as this more cleanly matches what the signal is doing at $t=-5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Lightbulb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ya_light = hilbert(y_light)\n",
    "\n",
    "light_phase = np.unwrap(np.angle(ya_light), discont=5)\n",
    "envelope = np.abs(ya_light)\n",
    "instant_freq = savgol_filter(light_phase, 3, 1, deriv=1, delta=x_light[1]-x_light[0], mode='mirror')/(2*np.pi)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6))\n",
    "axes[0].plot(x_light, y_light, color='k')\n",
    "axes[0].plot(x_light, np.imag(ya_light), color='r')\n",
    "axes[0].fill_between(x_light, -envelope, envelope, color='k', alpha=0.2)\n",
    "axes[0].set_title('Analytic response of light bulb', fontsize=20)\n",
    "axes[1].plot(fftshift(x_fft), fftshift(y_fft), color='r')\n",
    "axes[1].set_title('FFT', fontsize=20)\n",
    "axes[2].plot(x_light, instant_freq)\n",
    "axes[2].set_title('Hilbert Frequency', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Note:\n",
    "\n",
    "Scipy has two Hilbert transform functions, [`scipy.fftpack.hilbert`](https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.fftpack.hilbert.html) and [`scipy.signal.hilbert`](https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.signal.hilbert.html). It looks like the signal one is a bit more useful than the fftpack one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of the Hilbert Transform and Analytic Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathcal{H}(\\mathcal{H}(f(t)) = -f(t)$, up to a constant factor (and we'll get there in a bit...).\n",
    "- In Fourier space, the Hilbert transform multiplies the Fourier transform by $i \\times \\text{sgn}(\\nu)$. The transform to the analytic signal multiplies the Fourier transform by $2*\\Theta(t)$ where $\\Theta$ is the Heaviside function (0 at $t<0$, 1 at $t>0$). This means that we've basically cut out all of the negative frequency components of a signal.\n",
    "- The instantaneous frequency **BEATS** the Gabor limit $\\sigma_t \\sigma_{\\nu} \\geq 1/4\\pi$. If I was trying to use a spectrogram to figure out what frequency is happening right at the moment, I'd have to balance the width of the window--too wide and it's hard to tell exactly when something is happening, too narrow and I can't really distinguish between frequencies. We don't have that problem with the Hilbert transform.\n",
    "- The Hilbert transform is scale invariant--if we have a function $f_b(t) = f(bt)$, its Hilbert transform $\\mathcal{H}(f_b)(t) = \\mathcal{H}(f)(bt)$. Hence, I can blithely apply the Hilbert transforms (as above) and not have to worry about the $\\Delta x$ spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We run into some difficulties..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"up to a constant factor\" I mentioned in the first property ends up giving us some real headaches. For example, let's look at the function $f(t) = a + \\sin(\\pi t)$, where we adjust the constant factor $a$ (so we're looking at different reference values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### $a = 0$ (the case that works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-10, 10, 600)\n",
    "y_test = np.sin(np.pi*x_test) + 0.0\n",
    "ya_test = mirror_hilbert(y_test)\n",
    "dx = x_test[1]-x_test[0]\n",
    "\n",
    "envelope = np.abs(ya_test)\n",
    "phaseterm = np.unwrap(np.angle(ya_test))\n",
    "instant_freq0 = savgol_filter(phaseterm, 3, 1, deriv=1, delta=dx, mode='mirror')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11,5))\n",
    "\n",
    "axes[0].plot(x_test, np.real(ya_test), color='k', label='signal')\n",
    "axes[0].plot(x_test, np.imag(ya_test), color='r', label='HT')\n",
    "axes[0].fill_between(x_test, -envelope, envelope, color='k', alpha=0.2)\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].set_title('Signal', fontsize=14)\n",
    "axes[1].plot(x_test, phaseterm, color='g')\n",
    "axes[1].set_title('Phase', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### $a = 0.5$ (the functions are offset slightly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-10, 10, 600)\n",
    "y_test = np.sin(np.pi*x_test) + 0.5\n",
    "ya_test = mirror_hilbert(y_test, reflect_x=False)\n",
    "# Needed to be set to false here due to constant term\n",
    "dx = x_test[1]-x_test[0]\n",
    "\n",
    "envelope = np.abs(ya_test)\n",
    "phaseterm = np.unwrap(np.angle(ya_test))\n",
    "instant_freq03 = savgol_filter(phaseterm, 3, 1, deriv=1, delta=dx, mode='mirror')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11,5))\n",
    "\n",
    "axes[0].plot(x_test, np.real(ya_test), color='k', label='signal')\n",
    "axes[0].plot(x_test, np.imag(ya_test), color='r', label='HT')\n",
    "axes[0].fill_between(x_test, -envelope, envelope, color='k', alpha=0.2)\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].set_title('Signal', fontsize=14)\n",
    "axes[1].plot(x_test, phaseterm, color='g')\n",
    "axes[1].set_title('Phase', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### $a = 1.2$ (we don't even hit 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-10, 10, 600)\n",
    "y_test = np.sin(np.pi*x_test) + 1.2\n",
    "ya_test = mirror_hilbert(y_test, reflect_x=False)\n",
    "dx = x_test[1]-x_test[0]\n",
    "\n",
    "envelope = np.abs(ya_test)\n",
    "phaseterm = np.unwrap(np.angle(ya_test))\n",
    "instant_freq12 = savgol_filter(phaseterm, 3, 1, deriv=1, delta=dx, mode='mirror')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11,5))\n",
    "\n",
    "axes[0].plot(x_test, np.real(ya_test), color='k', label='signal')\n",
    "axes[0].plot(x_test, np.imag(ya_test), color='r', label='HT')\n",
    "axes[0].fill_between(x_test, -envelope, envelope, color='k', alpha=0.2)\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].set_title('Signal', fontsize=14)\n",
    "axes[1].plot(x_test, phaseterm, color='g')\n",
    "axes[1].set_title('Phase', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(x_test[30:-30], instant_freq0[30:-30], 'k', label='a = 0.0')\n",
    "plt.plot(x_test[30:-30], instant_freq03[30:-30], 'r', label='a = 0.5')\n",
    "plt.plot(x_test[30:-30], instant_freq12[30:-30], 'b', label='a = 1.2')\n",
    "plt.legend(bbox_to_anchor=(1.3, 1.05), fontsize=14)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.title(r'Hilbert frequencies for $sin(\\pi t) + a$', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additionally, if we have two dominant frequencies superimposed, we also see odd behavior\n",
    "\n",
    "$y = \\sin(\\pi x/2) + 0.5 \\cos(\\pi x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test2 = np.sin(np.pi*x_test/2) + 0.5*np.cos(np.pi*x_test)\n",
    "ya_test2 = hilbert(y_test2)\n",
    "# Signal is purely periodic, so not using mirror_hilbert\n",
    "\n",
    "envelope = np.abs(ya_test2)\n",
    "phaseterm = np.unwrap(np.angle(ya_test2))\n",
    "instant_freq2 = savgol_filter(phaseterm, 3, 1, deriv=1, delta=dx, mode='mirror')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14,5))\n",
    "\n",
    "axes[0].plot(x_test, np.real(ya_test2), color='k', label='signal')\n",
    "axes[0].plot(x_test, np.imag(ya_test2), color='r', label='HT')\n",
    "axes[0].fill_between(x_test, -envelope, envelope, color='k', alpha=0.2)\n",
    "# axes[0].plot(x_test, envelope, color='k', alpha=0.6, linestyle=':', label='envelope')\n",
    "# axes[0].plot(x_test, -envelope, color='k', alpha=0.6, linestyle=':')\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].set_title('Signal', fontsize=20)\n",
    "axes[1].plot(x_test, phaseterm, color='g')\n",
    "axes[1].set_title('Phase', fontsize=20)\n",
    "axes[2].plot(x_test, instant_freq2, color='k')\n",
    "axes[2].set_title('Frequency', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hilbert-Huang Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These problems were addressed by Norden Huang in [this paper](http://rspa.royalsocietypublishing.org/content/454/1971/903). The fundamental problem is that the Hilbert Transform works well provided you've got a signal that is centered around 0, and with zero crossings between the minima and maxima.\n",
    "\n",
    "So, we try and decompose our input signal into a collection of functions, called __Intrinsic Mode Functions__ (or IMFs) that *are* Hilbert-able.\n",
    "\n",
    "The procedure works as follows:\n",
    "- Take your signal, and compute two cubic splines--one that hits all the local maxima and one that hits all the local minima. These are our \"signal envelope\".\n",
    "- Take the mean of these two splines and subtract it from the signal.\n",
    "- The remaining signal is not necessarily Hilbert-able, but is closer to being so; we've centered the signal around 0 and the old minima and maxima should alternate on either side of 0, but our subtraction of the envelope mean may have caused new minima or maxima to occur.\n",
    "- From this signal, repeat the splines-and-subtract-mean process again and again. There's a couple of different stopping rules in the literature, but basically you'll stop when either the signal does not change appreciably from one iteration to another (Cauchy stoppage rules) or the number of zero-crossings and extrema are within a value of 1 and stay the same after *S* iterations (S stoppage). Both rules are explained more [here](http://www.msri.org/people/members/2008cc/Projects/Project_5B_Ice_Core_EMD/HuangWu_EMD_RevGeo_2008.pdf).\n",
    "- The signal you're left with is the first IMF, and gives good results under a Hilbert Transform.\n",
    "- Subtract the first IMF from the data, and then repeat the whole splines-mean-repeat process to get the second IMF, third IMF, and so on.\n",
    "- You'll stop getting IMFs when your remaining signal is either constant, monotonic or has at most one extremum. This is the residue, and is often thought of as the general trend.\n",
    "\n",
    "This whole process is called the __Emperical Mode Decomposition__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see this in action!\n",
    "\n",
    "[One application](https://web.cs.dal.ca/~tt/CSCI690611/papers/plugin-huan_asmbi_2003.pdf) proposed by Huang and others is in financial data, which we know is definitely non-stationary and probably a poor candidate for simple Fourier analysis.\n",
    "\n",
    "I've been sticking most of my IRA money into Vanguard Index Funds since 2013, so it's probably best for me to learn something about what's happening to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas.io.data as web\n",
    "import datetime as dt\n",
    "\n",
    "start = dt.datetime(2013, 5, 1)\n",
    "end = dt.datetime(2016, 5, 1)\n",
    "\n",
    "vti = web.DataReader(\"VTI\", \"google\", start, end)\n",
    "# Blah blah blah pandas wants me to install pandas_datareader, this still works for now...\n",
    "vti = vti['Close'] # I'll just keep opening prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vti.plot(color='k', linewidth=2, fontsize=15)\n",
    "plt.title(\"Tracking VTI\", fontsize=20)\n",
    "plt.xlabel(\"Date\", fontsize=20)\n",
    "plt.ylabel(\"Price at close ($)\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X0 = np.array(vti)\n",
    "print(X0[:5])\n",
    "dummy_t = np.arange(len(X0))  # So I don't have to futz with dates\n",
    "vti_dates = vti.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minima = sp.signal.argrelmin(X0)\n",
    "maxima = sp.signal.argrelmax(X0)\n",
    "\n",
    "minima_x = X0[minima]\n",
    "minima_t = dummy_t[minima]\n",
    "\n",
    "maxima_x = X0[maxima]\n",
    "maxima_t = dummy_t[maxima]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundary_N = -50\n",
    "restricted_t = dummy_t[boundary_N]\n",
    "bnd_max_t = maxima_t > restricted_t\n",
    "boundary_max_t = maxima_t[bnd_max_t]\n",
    "boundary_max_x = maxima_x[bnd_max_t]\n",
    "\n",
    "bnd_min_t = minima_t > restricted_t\n",
    "boundary_min_t = minima_t[bnd_min_t]\n",
    "boundary_min_x = minima_x[bnd_min_t]\n",
    "\n",
    "plt.plot(dummy_t[boundary_N:], X0[boundary_N:], color='k', label='VTI')\n",
    "plt.plot(boundary_max_t, boundary_max_x, linewidth=0, marker='o', color='r', label='maxima')\n",
    "plt.plot(boundary_min_t, boundary_min_x, linewidth=0, marker='d', color='b', label='minima')\n",
    "plt.legend(fontsize=16, loc=4)\n",
    "plt.title('Upper range of the data', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! How do we deal with the boundaries here? The minima and maxima functions don't point to the boundaries (which is good, those aren't necessarily minima or maxima) but if we want to do a cubic spline, we need a point at the boundary or outside of the data range in order to extend the spline. Some [potential options taken](http://www.worldscientific.com/doi/abs/10.1142/S1793536909000047) (free pdf [here](ftp://eos.atmos.washington.edu/pub/dennis/552_Class/Wu_Huang_EEMD_2005.pdf)) have been:\n",
    "- Only really look at the data far away from the boundaries. However, as we'll see in a bit, once you've gotten rid of some high-frequency components of your data, your extrema will be pretty close to the center and this might not be a great approach. Plus, we're probably interested data by the boundaries (I want to know what my retirement portfolio is going to do next! I can't just lop off the last two months...).\n",
    "- Mirror the data at the boundaries. We'd imagine that by reflecting the data we get a \"similar data process\" right by the boundary. However, this artifically introduces an extrema at the boundary point (well, you could get rid of this one, but that may be a judgement call), and the other extrema is at the exact same height as its previous image, which isn't necessarily justifiable.\n",
    "- Mirror and invert the data at the boundaries (and possibly translate it to match). We don't have the extrema showing up right at the boundary, but we're again making some pretty big assumptions about the location of extrema\n",
    "\n",
    "And, as we can see with our simple Hilbert transforms above, it was tricky enough to pick a mirror or mirror-and-invert approach uniformly without having to fuss a little bit with our data and make a judgement call.\n",
    "\n",
    "- Try and infer upcoming data using techniques like Fourier analysis, GARCH, Neural Networks, etc. But at this point you're doing an entirely different (and complicated) analysis, and some models (e.g. Fourier, ARMA...) assume stationarity--which is not necessarily justifiable.\n",
    "\n",
    "In the end, the strategy suggested in Wu and Huang's 2009 Ensemble Empirical Mode Decomposition paper (link above) is as follows:\n",
    "1. For both the minima and maxima, take the last two points (same type of extrema) before the boundary and draw a line between them.\n",
    "  - This isn't explicitly stated, but if you have only one minima or maxima you'll probably want to just extend a flat line in both directions.\n",
    "2. Look and see where these lines hit the boundary.\n",
    "3. If the data rises rises above the maxima line at the boundary (or below the minima line), use that as the boundary maxima (/minima). Otherwise use the point where the line hits the boundary as the maxima (/minima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_IMF_extrema(t, x):\n",
    "    noneoutput = (None, None, None, None)\n",
    "    minima = sp.signal.argrelmin(x)\n",
    "    maxima = sp.signal.argrelmax(x)\n",
    "    if isinstance(minima, tuple):\n",
    "        minima = minima[0]\n",
    "    if isinstance(maxima, tuple):\n",
    "        maxima = maxima[0]\n",
    "\n",
    "    if not len(minima):\n",
    "        print('No minima present')\n",
    "        return noneoutput\n",
    "    if not len(maxima):\n",
    "        print('No maxima present')\n",
    "        return noneoutput\n",
    "\n",
    "    if len(minima) == 1:\n",
    "        trial_xmin_start = x[minima]\n",
    "        trial_xmin_end = x[minima]\n",
    "    else:\n",
    "        xmin_1 = x[minima][0]\n",
    "        xmin_2 = x[minima][1]\n",
    "        tmin_1 = t[minima][0]\n",
    "        tmin_2 = t[minima][1]\n",
    "        min_start_slope = (xmin_2 - xmin_1)/(tmin_2 - tmin_1)\n",
    "        # x - x0 = m(t - t0)\n",
    "        # x = m(t - t0) + x0\n",
    "        trial_xmin_start = min_start_slope*(t[0] - tmin_1) + xmin_1\n",
    "\n",
    "        xmin_n1 = x[minima][-1]\n",
    "        xmin_n2 = x[minima][-2]\n",
    "        tmin_n1 = t[minima][-1]\n",
    "        tmin_n2 = t[minima][-2]\n",
    "        min_end_slope = (xmin_n2 - xmin_n1)/(tmin_n2 - tmin_n1)\n",
    "        trial_xmin_end = min_end_slope*(t[-1] - tmin_n1) + xmin_n1\n",
    "    \n",
    "    if len(maxima) == 1:\n",
    "        trial_xmax_start = x[maxima]\n",
    "        trial_xmax_end = x[maxima]\n",
    "    else:\n",
    "        xmax_1 = x[maxima][0]\n",
    "        xmax_2 = x[maxima][1]\n",
    "        tmax_1 = t[maxima][0]\n",
    "        tmax_2 = t[maxima][1]\n",
    "        max_start_slope = (xmax_2 - xmax_1)/(tmax_2 - tmax_1)\n",
    "        trial_xmax_start = max_start_slope*(t[0] - tmax_1) + xmax_1\n",
    "\n",
    "        xmax_n1 = x[maxima][-1]\n",
    "        xmax_n2 = x[maxima][-2]\n",
    "        tmax_n1 = t[maxima][-1]\n",
    "        tmax_n2 = t[maxima][-2]\n",
    "        max_end_slope = (xmax_n2 - xmax_n1)/(tmax_n2 - tmax_n1)\n",
    "        trial_xmax_end = max_end_slope*(t[-1] - tmax_n1) + xmax_n1\n",
    "\n",
    "    xmin_start = x[0] if x[0] < trial_xmin_start else trial_xmin_start\n",
    "    xmax_start = x[0] if x[0] > trial_xmax_start else trial_xmax_start\n",
    "    xmin_end = x[-1] if x[-1] < trial_xmin_end else trial_xmin_end\n",
    "    xmax_end = x[-1] if x[-1] > trial_xmax_end else trial_xmax_end\n",
    "    \n",
    "    minima_x = np.array([xmin_start] + list(x[minima]) + [xmin_end])\n",
    "    minima_t = np.array([t[0]] + list(t[minima]) + [t[-1]])\n",
    "    maxima_x = np.array([xmax_start] + list(x[maxima]) + [xmax_end])\n",
    "    maxima_t = np.array([t[0]] + list(t[maxima]) + [t[-1]])\n",
    "    return minima_x, minima_t, maxima_x, maxima_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minima_x, minima_t, maxima_x, maxima_t = get_IMF_extrema(dummy_t, X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundary_N = -50\n",
    "restricted_t = dummy_t[boundary_N]\n",
    "bnd_max_t = maxima_t > restricted_t\n",
    "boundary_max_t = maxima_t[bnd_max_t]\n",
    "boundary_max_x = maxima_x[bnd_max_t]\n",
    "\n",
    "bnd_min_t = minima_t > restricted_t\n",
    "boundary_min_t = minima_t[bnd_min_t]\n",
    "boundary_min_x = minima_x[bnd_min_t]\n",
    "\n",
    "boundary2_N = 50\n",
    "restricted_t2 = dummy_t[boundary2_N]\n",
    "bnd_max_t2 = maxima_t < restricted_t2\n",
    "boundary_max_t2 = maxima_t[bnd_max_t2]\n",
    "boundary_max_x2 = maxima_x[bnd_max_t2]\n",
    "\n",
    "bnd_min_t2 = minima_t < restricted_t2\n",
    "boundary_min_t2 = minima_t[bnd_min_t2]\n",
    "boundary_min_x2 = minima_x[bnd_min_t2]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "ax[0].plot(dummy_t[:boundary2_N], X0[:boundary2_N], color='k', label='VTI')\n",
    "ax[0].plot(boundary_max_t2, boundary_max_x2, linewidth=0, marker='o', color='r', label='maxima')\n",
    "ax[0].plot(boundary_min_t2, boundary_min_x2, linewidth=0, marker='d', color='b', label='minima')\n",
    "ax[0].legend(fontsize=16, loc=1)\n",
    "ax[0].set_title('Lower range of the data', fontsize=20)\n",
    "\n",
    "ax[1].plot(dummy_t[boundary_N:], X0[boundary_N:], color='k', label='VTI')\n",
    "ax[1].plot(boundary_max_t, boundary_max_x, linewidth=0, marker='o', color='r', label='maxima')\n",
    "ax[1].plot(boundary_min_t, boundary_min_x, linewidth=0, marker='d', color='b', label='minima')\n",
    "ax[1].legend(fontsize=16, loc=4)\n",
    "ax[1].set_title('Upper range of the data', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed fitting splines to our extrema to get envelopes, and then subtract the envelope mean out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_spline = sp.interpolate.interp1d(minima_t, minima_x, kind='cubic')\n",
    "max_spline = sp.interpolate.interp1d(maxima_t, maxima_x, kind='cubic')\n",
    "\n",
    "m1 = (max_spline(dummy_t) + min_spline(dummy_t))/2\n",
    "h1 = X0 - m1\n",
    "\n",
    "plt.plot(dummy_t, h1, color='k')\n",
    "plt.title(\"Prototype first IMF\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better, but we should subtract out the envelope mean a few more times to see the signal settle in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HHT_IMF_prototype(t, x, Niter=5, verbose=False):\n",
    "    N = len(t)\n",
    "    out_x = np.zeros((N, Niter))\n",
    "    for idx in range(Niter):\n",
    "        if verbose:\n",
    "            print('Running %d of %d' % (idx + 1, Niter))\n",
    "        \n",
    "        minima_x, minima_t, maxima_x, maxima_t = get_IMF_extrema(t, x)\n",
    "        if minima_x is None:\n",
    "            raise ValueError('Signal given should be your residue.')\n",
    "        \n",
    "        if len(minima_t) != 3:\n",
    "            min_spline = sp.interpolate.interp1d(minima_t, minima_x, kind='cubic')\n",
    "        else:\n",
    "            # You need 4 points for a cubic spline, so use quadratic\n",
    "            min_spline = sp.interpolate.interp1d(minima_t, minima_x, kind='quadratic')\n",
    "        \n",
    "        if len(maxima_t) != 3:\n",
    "            max_spline = sp.interpolate.interp1d(maxima_t, maxima_x, kind='cubic')\n",
    "        else:\n",
    "            max_spline = sp.interpolate.interp1d(maxima_t, maxima_x, kind='quadratic')\n",
    "\n",
    "        env_mean = (min_spline(t) + max_spline(t))/2\n",
    "        x = x - env_mean\n",
    "        out_x[:, idx] = x\n",
    "    return out_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1_series = HHT_IMF_prototype(dummy_t, h1, Niter=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(14,14))\n",
    "axes[0].plot(dummy_t, h1_series[:,0], color='r', label='new')\n",
    "axes[0].plot(dummy_t, h1, color='k', label='old')\n",
    "axes[0].legend(fontsize=15, loc=4)\n",
    "axes[0].set_ylabel(r\"$h_{1,1}$\", fontsize=15)\n",
    "axes[1].plot(dummy_t, h1_series[:,1], color='r', label='new')\n",
    "axes[1].plot(dummy_t, h1_series[:,0], color='k', label='old')\n",
    "axes[1].legend(fontsize=15, loc=4)\n",
    "axes[1].set_ylabel(r\"$h_{1,2}$\", fontsize=15)\n",
    "axes[2].plot(dummy_t, h1_series[:,2], color='r', label='new')\n",
    "axes[2].plot(dummy_t, h1_series[:,1], color='k', label='old')\n",
    "axes[2].legend(fontsize=15, loc=4)\n",
    "axes[2].set_ylabel(r\"$h_{1,3}$\", fontsize=15)\n",
    "axes[3].plot(dummy_t, h1_series[:,3], color='r', label='new')\n",
    "axes[3].plot(dummy_t, h1_series[:,2], color='k', label='old')\n",
    "axes[3].legend(fontsize=15, loc=4)\n",
    "axes[3].set_ylabel(r\"$h_{1,4}$\", fontsize=15)\n",
    "axes[4].plot(dummy_t, h1_series[:,4], color='r', label='new')\n",
    "axes[4].plot(dummy_t, h1_series[:,3], color='k', label='old')\n",
    "axes[4].legend(fontsize=15, loc=4)\n",
    "axes[4].set_ylabel(r\"$h_{1,5}$\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the 5th iteration, it looks like the signal is pretty static, so we'll say that we've settled on the first IMF ($h_{1,5}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMF1 = h1_series[:,-1]\n",
    "X1 = X0 - IMF1\n",
    "\n",
    "plt.plot(vti_dates, X0, color='k', label='VTI')\n",
    "plt.plot(vti_dates, X1, color='r', label='VTI - IMF1')\n",
    "plt.legend(fontsize=15, loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the remaining signal has much of the high-frequency stuff filtered out.\n",
    "\n",
    "Repeating this again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2_series = HHT_IMF_prototype(dummy_t, X1, Niter=6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(14,18))\n",
    "axes[0].plot(dummy_t, h2_series[:,0], color='r')\n",
    "axes[0].set_ylabel(r\"$h_{2,0}$\", fontsize=15)\n",
    "axes[1].plot(dummy_t, h2_series[:,1], color='r', label='new')\n",
    "axes[1].plot(dummy_t, h2_series[:,0], color='k', label='old')\n",
    "axes[1].legend(fontsize=15)\n",
    "axes[1].set_ylabel(r\"$h_{2,1}$\", fontsize=15)\n",
    "axes[2].plot(dummy_t, h2_series[:,2], color='r', label='new')\n",
    "axes[2].plot(dummy_t, h2_series[:,1], color='k', label='old')\n",
    "axes[2].legend(fontsize=15)\n",
    "axes[2].set_ylabel(r\"$h_{2,2}$\", fontsize=15)\n",
    "axes[3].plot(dummy_t, h2_series[:,3], color='r', label='new')\n",
    "axes[3].plot(dummy_t, h2_series[:,2], color='k', label='old')\n",
    "axes[3].legend(fontsize=15)\n",
    "axes[3].set_ylabel(r\"$h_{2,3}$\", fontsize=15)\n",
    "axes[4].plot(dummy_t, h2_series[:,4], color='r', label='new')\n",
    "axes[4].plot(dummy_t, h2_series[:,3], color='k', label='old')\n",
    "axes[4].legend(fontsize=15)\n",
    "axes[4].set_ylabel(r\"$h_{2,4}$\", fontsize=15)\n",
    "axes[5].plot(dummy_t, h2_series[:,5], color='r', label='new')\n",
    "axes[5].plot(dummy_t, h2_series[:,4], color='k', label='old')\n",
    "axes[5].legend(fontsize=15)\n",
    "axes[5].set_ylabel(r\"$h_{2,5}$\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMF2 = h2_series[:,-1]\n",
    "X2 = X1 - IMF2\n",
    "\n",
    "plt.plot(vti_dates, X0, color='k', label='VTI')\n",
    "plt.plot(vti_dates, X2, color='r', label='VTI - IMF1 - IMF2')\n",
    "plt.legend(fontsize=15, loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to automate this process more, so I'll now use the S stoppage rule (number of extrema and zero-crossings within one of each other, number of extrema and zero crossings does not change for 5 iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_next_IMF(X_i, S_finish=5, maxiter=50, extra_verbose=False):\n",
    "    print(\"Calulating h_i0\")\n",
    "    t = np.arange(len(X_i))\n",
    "    S_accum = 0\n",
    "    h_i = HHT_IMF_prototype(t, X_i, Niter=1).ravel()\n",
    "\n",
    "    # Find number of maxima and zero crossings\n",
    "    minima = sp.signal.argrelmin(h_i)\n",
    "    if isinstance(minima, tuple):\n",
    "        minima = minima[0]\n",
    "    maxima = sp.signal.argrelmax(h_i)[0]\n",
    "    if isinstance(maxima, tuple):\n",
    "        maxima = maxima[0]\n",
    "    # argrel doesn't pick points on the boundaries, fortunately\n",
    "    zerocrossdown = np.logical_and(h_i[:-1] >= 0, h_i[1:] < 0)\n",
    "    zerocrossup = np.logical_and(h_i[:-1] <= 0, h_i[1:] > 0)\n",
    "    \n",
    "    numextrema = len(minima) + len(maxima)\n",
    "    numzeros = sum(zerocrossdown) + sum(zerocrossup)\n",
    "    old_numextrema = numextrema\n",
    "    old_numzeros = numzeros\n",
    "    \n",
    "    idx = 1\n",
    "    while S_accum < S_finish:\n",
    "        print(\"Beginning iter %s\" % idx)\n",
    "        \n",
    "        h_i = HHT_IMF_prototype(t, h_i, Niter=1, verbose=extra_verbose).ravel()\n",
    "        \n",
    "        minima = sp.signal.argrelmin(h_i)\n",
    "        if isinstance(minima, tuple):\n",
    "            minima = minima[0]\n",
    "        maxima = sp.signal.argrelmax(h_i)\n",
    "        if isinstance(maxima, tuple):\n",
    "            maxima = maxima[0]\n",
    "        zerocrossdown = np.logical_and(h_i[:-1] >= 0, h_i[1:] < 0)\n",
    "        zerocrossup = np.logical_and(h_i[:-1] <= 0, h_i[1:] > 0)\n",
    "    \n",
    "        numextrema = len(minima) + len(maxima)\n",
    "        numzeros = sum(zerocrossdown) + sum(zerocrossup)\n",
    "        \n",
    "        test1 = np.abs(numextrema - numzeros) <= 1\n",
    "        test2 = numextrema == old_numextrema\n",
    "        test3 = numzeros == old_numzeros\n",
    "        \n",
    "        old_numextrema = numextrema\n",
    "        old_numzeros = numzeros\n",
    "        \n",
    "        if test1 and test2 and test3:\n",
    "            print(\"Passed S\")\n",
    "            S_accum += 1\n",
    "        else:\n",
    "            print(\"Failed S\")\n",
    "            S_accum = 0\n",
    "        if idx == maxiter:\n",
    "            print(\"Reached maxiter\")\n",
    "            break\n",
    "        idx += 1\n",
    "    return h_i, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Redoing the calc of IMF1 and 2 above, since it's difficult to check IMF1 by eye\n",
    "# to ensure we're stopping appropriately.\n",
    "IMF1, _ = calculate_next_IMF(X0)\n",
    "X1 = X0 - IMF1\n",
    "IMF2, _ = calculate_next_IMF(X1)\n",
    "X1 = X0 - IMF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMF3, _ = calculate_next_IMF(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dummy_t, IMF3, color='k')\n",
    "plt.title(\"IMF3\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3 = X2 - IMF3\n",
    "IMF4, _ = calculate_next_IMF(X3)\n",
    "plt.plot(dummy_t, IMF4, color='k')\n",
    "plt.title(\"IMF4\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4 = X3 - IMF4\n",
    "IMF5, _ = calculate_next_IMF(X4)\n",
    "plt.plot(dummy_t, IMF5, color='k')\n",
    "plt.title(\"IMF5\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5 = X4 - IMF5\n",
    "plt.plot(dummy_t, X5, color='k')\n",
    "\n",
    "print(sp.signal.argrelmin(X5))\n",
    "print(sp.signal.argrelmax(X5))\n",
    "plt.plot(dummy_t, X5, 'k')\n",
    "plt.plot(dummy_t[[519, 695]], X5[[519, 695]], linewidth=0, marker='o', color='r')\n",
    "print(X5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have just two extrema left, so the next IMF will be our last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMF6, _ = calculate_next_IMF(X5)\n",
    "plt.plot(dummy_t, IMF6, color='k')\n",
    "plt.title(\"IMF6\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residue = X5 - IMF6\n",
    "plt.plot(dummy_t, X0, color='k', label=\"VTI\")\n",
    "plt.plot(dummy_t, residue, color='r', label=\"residue\")\n",
    "plt.legend(fontsize=15, loc=4)\n",
    "plt.title(\"Residue and original VTI\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(14,22))\n",
    "axes[0].plot(vti_dates, X0, color='r')\n",
    "axes[0].set_ylabel(\"Original\", fontsize=15)\n",
    "axes[0].set_title(\"EMD of VTI stock over 4 years\", fontsize=20)\n",
    "axes[1].plot(vti_dates, IMF1, color='k')\n",
    "axes[1].set_ylabel(r\"IMF1\", fontsize=15)\n",
    "\n",
    "axes[2].plot(vti_dates, IMF2, color='k')\n",
    "axes[2].set_ylabel(r\"IMF2\", fontsize=15)\n",
    "\n",
    "axes[3].plot(vti_dates, IMF3, color='k')\n",
    "axes[3].set_ylabel(r\"IMF3\", fontsize=15)\n",
    "\n",
    "axes[4].plot(vti_dates, IMF4, color='k')\n",
    "axes[4].set_ylabel(r\"IMF4\", fontsize=15)\n",
    "\n",
    "axes[5].plot(vti_dates, IMF5, color='k')\n",
    "axes[5].set_ylabel(r\"IMF5\", fontsize=15)\n",
    "\n",
    "axes[6].plot(vti_dates, IMF6, color='k')\n",
    "axes[6].set_ylabel(r\"IMF6\", fontsize=15)\n",
    "\n",
    "axes[7].plot(vti_dates, residue, color='b')\n",
    "axes[7].set_ylabel(r\"Residue\", fontsize=15)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At this point the performance of VTI stock has been broken into 6 Hilbert-able frequency components.\n",
    "\n",
    "Getting the frequency components..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMF_hil = mirror_hilbert(IMF1, reflect_x=False)\n",
    "\n",
    "env1 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "# phase = savgol_filter(phase, 7, 3, deriv=0, mode='mirror')\n",
    "freq1 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "# delta = 1 day. I'm going to multiply by 7 to get weekly freqs for something a bit\n",
    "# more human readable\n",
    "\n",
    "# The Hilbert signal we're getting here jumps below 0 at some times still. For this,\n",
    "# we clip below min_freq_thresh\n",
    "# min_freq_thresh = 0.005\n",
    "# Trying to clean out more weird bits, I'm use one final SG filter to clean out neg signals\n",
    "# freq1 = savgol_filter(freq1, 7, 3, deriv=0, mode='mirror')\n",
    "# freq1[freq1 < min_freq_thresh] = min_freq_thresh\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF2, reflect_x=False)\n",
    "\n",
    "env2 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "# phase = savgol_filter(phase, 7, 3, deriv=0, mode='mirror')\n",
    "freq2 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "# freq2 = savgol_filter(freq2, 5, 3, deriv=0, mode='mirror')\n",
    "# freq2[freq2 < min_freq_thresh] = min_freq_thresh\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF3, reflect_x=False)\n",
    "\n",
    "env3 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "# phase = savgol_filter(phase, 7, 3, deriv=0, mode='mirror')\n",
    "freq3 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "# freq3 = savgol_filter(freq3, 5, 3, deriv=0, mode='mirror')\n",
    "# freq3[freq3 < min_freq_thresh] = min_freq_thresh\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF4, reflect_x=False)\n",
    "\n",
    "env4 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "# phase = savgol_filter(phase, 7, 3, deriv=0, mode='mirror')\n",
    "freq4 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "# freq4 = savgol_filter(freq4, 5, 3, deriv=0, mode='mirror')\n",
    "# freq4[freq4 < min_freq_thresh] = min_freq_thresh\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF5, reflect_x=False)\n",
    "\n",
    "env5 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "# phase = savgol_filter(phase, 7, 3, deriv=0, mode='mirror')\n",
    "freq5 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "# freq5 = savgol_filter(freq5, 5, 3, deriv=0, mode='mirror')\n",
    "# freq5[freq5 < min_freq_thresh] = min_freq_thresh\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF6, reflect_x=False)\n",
    "\n",
    "env6 = np.abs(IMF_hil)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "freq6 = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 14))\n",
    "axes.plot(vti_dates, freq1, color='k', label='IMF1')\n",
    "axes.plot(vti_dates, freq2, color='r', label='IMF2')\n",
    "axes.plot(vti_dates, freq3, color='b', label='IMF3')\n",
    "axes.plot(vti_dates, freq4, color='g', label='IMF4')\n",
    "axes.plot(vti_dates, freq5, color='m', label='IMF5')\n",
    "axes.plot(vti_dates, freq5, color='y', label='IMF6')\n",
    "axes.set_xlabel(\"Date\", fontsize=20)\n",
    "axes.set_ylabel(\"Frequency [1/wk]\", fontsize=20)\n",
    "axes.set_title(\"HT frequencies of EMD\", fontsize=20)\n",
    "axes.tick_params(labelsize=20)\n",
    "axes.legend(fontsize=16, loc=4)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Well, that's disappointing--we seem to have some nice-ish looking parts, but then we also have violent spikes in the frequencies. These signals aren't so Hilbertable after all! :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A footnote comes back to haunt us...\n",
    "\n",
    "I mentioned in a footnote far above (when introducing the analytic signal) that our inferring the instantaneous frequency from $\\tilde{f}(t) = A(t)e^{i \\theta(t) t}$ only works properly if the frequency content of $A(t)$ and $e^{i \\theta(t) t}$ have no overlap (due to the Bedrosian Theorem). So what happens when we try and plot the inferred envelope with the signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dummy_t, IMF3, color='k')\n",
    "plt.fill_between(dummy_t, -env3, env3, color='k', alpha=0.2)\n",
    "plt.title('IMF3 and its envelope', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bueno. We can easily see the envelope is bouncing around with the same frequency as the IMF itself.\n",
    "\n",
    "To get around this issue, some further work is to be done on our IMFs. Since we need the frequency content of envelope to be disjoint from the frequency content of the oscillating signal, we will first try and munge our signal into something that's normalized (a constant envelope of size 1), compute the instantaneous frequency from there, and then back out to get the envelope.\n",
    "\n",
    "The process goes as follows:\n",
    "1. Take the absolute value of the IMF, and find all its maxima.\n",
    "2. Fit a cubic spline to the maxima (we'll call it $e_1$).\n",
    "3. Divide the IMF by $e_1$. The signal should mostly oscillate between -1 and 1, but there may be some bits that exceed this (if the spline happened to go beneath a signal).\n",
    "4. Repeat the process above (getting splines $e_2, e_3, ..., e_n$ until all of the signal lies between -1 and 1. This generally only takes a few tries.\n",
    "\n",
    "After this whole process, your envelope $A(t)$ is the product $e_1 \\times ... \\times e_n$ and the frequency signal is the IMF divided by $A$. Analogous to radio signals, we call the envelope the AM (amplitude modulation) signal and the frequency signal the FM signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "absIMF3 = np.abs(IMF3)\n",
    "_, _, maxima_x, maxima_t = get_IMF_extrema(dummy_t, absIMF3)\n",
    "e1fn = sp.interpolate.interp1d(maxima_t, maxima_x, kind='cubic')\n",
    "e1 = e1fn(dummy_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dummy_t, IMF3/e1, color='k')\n",
    "plt.title('IMF3 after first normalization', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_IMF_to_AM_FM(dummy_t, IMF, max_iter=10, verbose=True):\n",
    "    IMForiginal = np.copy(IMF)\n",
    "    N = len(dummy_t)\n",
    "    en_array = np.ones((N, max_iter))\n",
    "    \n",
    "    for idx in range(max_iter):\n",
    "        if verbose:\n",
    "            print('Running normalization %d' % (idx + 1))\n",
    "        IMFabs = np.abs(IMF)\n",
    "        _, _, maxima_x, maxima_t = get_IMF_extrema(dummy_t, IMFabs)\n",
    "        en_fn = sp.interpolate.interp1d(maxima_t, maxima_x, kind='cubic')\n",
    "        e_n = en_fn(dummy_t)\n",
    "        IMF = IMF/e_n\n",
    "        en_array[:, idx] = e_n\n",
    "        if all(np.abs(IMF) <= 1 + 1E-9):\n",
    "            # Added tolerance value, otherwise it doesn't stop\n",
    "            maximf = np.max(IMF)\n",
    "            IMF = IMF/maximf\n",
    "            break\n",
    "        if idx == max_iter - 1:\n",
    "            print('Reached max_iter')\n",
    "    FM = IMF\n",
    "    AM = np.prod(en_array, axis=1)\n",
    "    return AM, FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AM, FM = split_IMF_to_AM_FM(dummy_t, IMF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "ax[0].plot(dummy_t, env3, color='k', label='Naive Hilbert envelope')\n",
    "ax[0].plot(dummy_t, AM, color='r', label='AM envelope')\n",
    "ax[0].legend(fontsize=16, loc=2)\n",
    "ax[0].set_title(\"IMF3 envelope after normalization\", fontsize=20)\n",
    "\n",
    "ax[1].plot(dummy_t, IMF3, color='k', label='IMF')\n",
    "ax[1].fill_between(dummy_t, -AM, AM, color='k', alpha=0.2)\n",
    "ax[1].set_title(\"IMF3 and AM envelope\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two methods of getting instantaneous frequency\n",
    "\n",
    "(For a deeper look Huang et al.'s paper \"On Instantaneous Frequency\" ([link](http://www.worldscientific.com/doi/abs/10.1142/S1793536909000096)))\n",
    "\n",
    "Now that we have a normalized FM signal, we have a few different methods available to us to process it.\n",
    "\n",
    "First, we can finally use the Hilbert Transform on the normalized signal, confident now that the envelope won't look like a phase component to the transform. This technique is called the __Normalized Hilbert Transform (NHT)__. However, we still have some of the problems we saw at the beginning of boundaries still being a bit weird (and since we're integrating over the whole signal, this affects everything.\n",
    "\n",
    "A different technique, called __Direct Quadrature (DQ)__ avoids this, and is currently the technique most in use. If we assume that our normalized signal has some form $F(t) = \\cos(\\phi(t))$ (for some unknown $\\phi(t)$), we assume there's some complementary signal $G(t) = \\sin(\\phi(t))$. Now, the trick is just to find $\\phi$. You could take the arccosine of $F$, but it ends up being easier if you take\n",
    "\n",
    "$$\\phi(t) = \\arctan \\left( \\frac{G}{F}\\right) = \\arctan \\left( \\frac{\\sqrt{1 - F^2}}{F}\\right)$$\n",
    "\n",
    "and then upwrap $\\phi$ as necessary.\n",
    "\n",
    "I realize that, after a long process of dealing with Hilbert Transforms, we've arrived at an algorithm that actually doesn't have a Hilbert Transform in it. I hope we can all appreciate the irony in this situation.\n",
    "\n",
    "With that said, for the sake of quick illustration I'll use the NHT instead of DQ to get the frequency content of VTI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NHT = mirror_hilbert(FM)\n",
    "\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "IMF_hil = mirror_hilbert(IMF3, reflect_x=False)\n",
    "phase = np.unwrap(np.angle(IMF_hil))\n",
    "instant_freq_HT = 7*savgol_filter(phase, 5, 3, deriv=1, delta=1, mode='mirror')/(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dummy_t, instant_freq_HT, color='k', label='HT frequency')\n",
    "plt.plot(dummy_t, instant_freq_FM, color='r', label='NHT frequency')\n",
    "plt.ylabel('Frequency [1/wk]', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.title('Instantaneous frequency of IMF3 from the HT and NHT', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the NHT's frequency is much better behaved, without the sudden spikes. If we used Direct Quadrature, this would be even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AM1, FM = split_IMF_to_AM_FM(dummy_t, IMF1)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM1 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "AM2, FM = split_IMF_to_AM_FM(dummy_t, IMF2)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM2 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "AM3, FM = split_IMF_to_AM_FM(dummy_t, IMF3)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM3 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "AM4, FM = split_IMF_to_AM_FM(dummy_t, IMF4)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM4 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "AM5, FM = split_IMF_to_AM_FM(dummy_t, IMF5)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM5 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)\n",
    "\n",
    "AM6, FM = split_IMF_to_AM_FM(dummy_t, IMF6)\n",
    "NHT = mirror_hilbert(FM)\n",
    "phaseterm = np.unwrap(np.angle(NHT))\n",
    "instant_freq_FM6 = 7*savgol_filter(phaseterm, 3, 1, deriv=1, delta=1, mode='mirror')/(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 14))\n",
    "axes.plot(vti_dates, freq1, color='k', label='IMF1')\n",
    "axes.plot(vti_dates, freq2, color='r', label='IMF2')\n",
    "axes.plot(vti_dates, freq3, color='b', label='IMF3')\n",
    "axes.plot(vti_dates, freq4, color='g', label='IMF4')\n",
    "axes.plot(vti_dates, freq5, color='m', label='IMF5')\n",
    "axes.plot(vti_dates, freq6, color='y', label='IMF6')\n",
    "axes.set_xlabel(\"Date\", fontsize=20)\n",
    "axes.set_ylabel(\"Frequency [1/wk]\", fontsize=20)\n",
    "axes.set_title(\"HT frequencies of EMD\", fontsize=20)\n",
    "axes.tick_params(labelsize=20)\n",
    "axes.legend(fontsize=16, loc=4)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 14))\n",
    "axes.plot(vti_dates, instant_freq_FM1, color='k', label='IMF1')\n",
    "axes.plot(vti_dates, instant_freq_FM2, color='r', label='IMF2')\n",
    "axes.plot(vti_dates, instant_freq_FM3, color='b', label='IMF3')\n",
    "axes.plot(vti_dates, instant_freq_FM4, color='g', label='IMF4')\n",
    "axes.plot(vti_dates, instant_freq_FM5, color='m', label='IMF5')\n",
    "axes.plot(vti_dates, instant_freq_FM6, color='y', label='IMF6')\n",
    "axes.set_xlabel(\"Date\", fontsize=20)\n",
    "axes.set_ylabel(\"Frequency [1/wk]\", fontsize=20)\n",
    "axes.set_title(\"NHT frequencies of EMD\", fontsize=20)\n",
    "axes.tick_params(labelsize=20)\n",
    "axes.legend(fontsize=16, loc=4)\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the first IMF still has instability, it's much better (and we should probably impute points and use DQ to clean it up further). Meanwhile, the rest of the instantaneous frequencies look much better. Now, plotting in log-y (without IMF1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 14))\n",
    "# axes.plot(vti_dates, instant_freq_FM1, color='k', label='IMF1')\n",
    "axes.semilogy(vti_dates, instant_freq_FM2, color='r', label='IMF2')\n",
    "axes.semilogy(vti_dates, instant_freq_FM3, color='b', label='IMF3')\n",
    "axes.semilogy(vti_dates, instant_freq_FM4, color='g', label='IMF4')\n",
    "axes.semilogy(vti_dates, instant_freq_FM5, color='m', label='IMF5')\n",
    "axes.semilogy(vti_dates, instant_freq_FM6, color='y', label='IMF6')\n",
    "axes.set_xlabel(\"Date\", fontsize=20)\n",
    "axes.set_ylabel(\"Frequency [1/wk]\", fontsize=20)\n",
    "axes.set_title(\"NHT frequencies of EMD\", fontsize=20)\n",
    "axes.tick_params(labelsize=20)\n",
    "axes.legend(fontsize=16, loc=4)\n",
    "axes.set_ylim([1E-2, 0.3*1E1])\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pretty clearly see that IMF2 corresponds to approximately weekly variation, IMF3 to monthly, IMF5 about year-long, and a few other signals beside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 14))\n",
    "axes.semilogy(vti_dates, AM1, color='k', label='IMF1')\n",
    "axes.semilogy(vti_dates, AM2, color='r', label='IMF2')\n",
    "axes.semilogy(vti_dates, AM3, color='b', label='IMF3')\n",
    "axes.semilogy(vti_dates, AM4, color='g', label='IMF4')\n",
    "axes.semilogy(vti_dates, AM5, color='m', label='IMF5')\n",
    "axes.semilogy(vti_dates, AM6, color='y', label='IMF6')\n",
    "axes.set_xlabel(\"Date\", fontsize=20)\n",
    "axes.set_ylabel(\"Amplitude [$]\", fontsize=20)\n",
    "axes.set_title(\"AM amplitudes of EMD\", fontsize=20)\n",
    "axes.tick_params(labelsize=20)\n",
    "axes.legend(fontsize=16, loc=4)\n",
    "# axes.set_ylim([1E-2, 0.3*1E1])\n",
    "\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we learn? Well, some initial things I see:\n",
    "- The [great stock sell-off around September 2015](https://en.wikipedia.org/wiki/2015_stock_market_selloff) is pretty clear in the highest-frequency IMF (IMF1). There's also some high-frequency action around May 2014, though I'm not finding any direct noise ([rapid-fire mergers and acquisitions](https://en.wikipedia.org/wiki/2015_stock_market_selloff)?).\n",
    "- Outside of the above events, just by eyeing the amplitudes of the IMFs the high-frequency stuff is generally of less importance than the lower-frequency IMFs. But hey, we are looking at the broad markets, here.\n",
    "- We can especially see the broad motions of VTI in the residue, with it peaking around summer of 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further notes:\n",
    "\n",
    "- Another major extension is the Ensemble Empirical Mode Decomposition (EEMD). For this technique, you add white-noise to the signal before you begin the EMD. Do this multiple times, and then average the IMFs together to cancel out the noise effects. This is especially useful if you have intermittant frequency signals, since those will play havoc with your IMFs.\n",
    "- While using an arctangent for Direct Quadrature improves computational stability versus arccosine, it still may have trouble at the highest frequencies as the extrema may not map cleanly onto the data points. The authors recommends a 3-point-medium filter on the data, which seems to be unstandard terminology which I'm not seeing in the literature but which I assume means we might want to try and impute potential points using a LOESS strategy (e.g. with polynomials via Savitsky Golay).\n",
    "- Once you've gotten your instantaneous frequencies and envelopes, you can calculate the marginal Hilbert spectrum as\n",
    "$$H(\\omega) = \\int IMF(\\omega, t) dt$$\n",
    "  (IMF is zero unless we're at $\\omega$, at which point you add the value of its envelope amplitude) to get the frequency content of the signal. This lets you know, as you add IMFs together, what frequencies you're including.\n",
    "- There are [Python](https://pyhht.readthedocs.org/en/latest/) and [R](https://cran.r-project.org/web/packages/hht/index.html) packages to do the EMD for you.\n",
    "- The EMD technique is currently under patent. For commercial use, you'll need to speak with NASA's Office of Technology Tranfer (patent numbers: 9013490, 8144331, 8913844, reference number GSC-TOPS-63)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
